# üöÄ Configuraci√≥n de Embeddings con Google Gemini

## ‚úÖ VENTAJAS DE USAR GEMINI

- ‚úÖ **GRATIS** (1,500 requests/d√≠a en tier gratuito)
- ‚úÖ **Sin problemas de regi√≥n** (funciona globalmente)
- ‚úÖ **F√°cil de configurar** (solo API key)
- ‚úÖ **Buena calidad** (768 dimensiones suficientes para tu caso)
- ‚ö†Ô∏è **Requiere ajustar pgvector** (de 1536 a 768 dimensiones)

---

## üìã PASO 1: OBTENER API KEY

### 1.1 Ir a Google AI Studio
```
URL: https://aistudio.google.com/app/apikey
```

### 1.2 Crear API Key
1. Click **"Get API key"** o **"Create API key"**
2. Selecciona un proyecto de Google Cloud
   - O click **"Create API key in new project"**
3. Copia la API key (formato: `AIzaSy...`)
4. ‚ö†Ô∏è **Gu√°rdala en lugar seguro**

---

## üìã PASO 2: ACTUALIZAR `.env`

Agreg√° estas l√≠neas al archivo `.env`:

```bash
# ============================================================================
# GEMINI - EMBEDDINGS
# ============================================================================
EMBEDDING_PROVIDER=gemini
GEMINI_API_KEY=AIzaSy_TU_API_KEY_AQUI
```

**Dej√° las variables de Azure OpenAI** (se siguen usando para el chat):
```bash
AI_PROVIDER=azure
AZURE_OPENAI_API_KEY=...
AZURE_OPENAI_ENDPOINT=...
AZURE_OPENAI_DEPLOYMENT=gpt-4-deployment  # Para chat
```

---

## üìã PASO 3: INSTALAR DEPENDENCIA

Agreg√° al `requirements.txt`:

```bash
google-generativeai==0.3.2
```

O instala directamente en el contenedor:

```bash
docker exec analizador-backend pip install google-generativeai==0.3.2
```

---

## üìã PASO 4: AJUSTAR DIMENSIONES EN PGVECTOR

### Opci√≥n A: Recrear Tablas (RECOMENDADO si no ten√©s datos)

```bash
docker exec analizador-postgres psql -U unlam -d analizador_financiero << EOF
-- Eliminar tablas viejas
DROP TABLE IF EXISTS gastos_embeddings CASCADE;
DROP TABLE IF EXISTS ingresos_embeddings CASCADE;

-- Recrear con 768 dimensiones
CREATE TABLE gastos_embeddings (
    id SERIAL PRIMARY KEY,
    gasto_id INTEGER NOT NULL UNIQUE REFERENCES gastos(id_gasto) ON DELETE CASCADE,
    embedding vector(768) NOT NULL,  -- 768 dimensiones (Gemini)
    texto_original TEXT NOT NULL,
    metadata JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE TABLE ingresos_embeddings (
    id SERIAL PRIMARY KEY,
    ingreso_id INTEGER NOT NULL UNIQUE REFERENCES ingresos(id_ingreso) ON DELETE CASCADE,
    embedding vector(768) NOT NULL,  -- 768 dimensiones (Gemini)
    texto_original TEXT NOT NULL,
    metadata JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- √çndices
CREATE INDEX idx_gastos_embeddings_gasto_id ON gastos_embeddings(gasto_id);
CREATE INDEX idx_gastos_embeddings_metadata ON gastos_embeddings USING gin(metadata);
CREATE INDEX idx_ingresos_embeddings_ingreso_id ON ingresos_embeddings(ingreso_id);
CREATE INDEX idx_ingresos_embeddings_metadata ON ingresos_embeddings USING gin(metadata);

-- √çndices vectoriales (crear despu√©s de tener datos)
-- CREATE INDEX idx_gastos_embeddings_vector ON gastos_embeddings USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
-- CREATE INDEX idx_ingresos_embeddings_vector ON ingresos_embeddings USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
EOF
```

### Opci√≥n B: Script Autom√°tico

```bash
cd backend
docker exec analizador-postgres psql -U unlam -d analizador_financiero -f /docker-entrypoint-initdb.d/recreate_embeddings_768.sql
```

---

## üìã PASO 5: ACTUALIZAR MODELOS SQLALCHEMY

Ya est√° actualizado el `embeddings_service.py`, pero necesit√°s actualizar `models/embeddings.py`:

**Cambio necesario:**
```python
# DE:
embedding = Column(Vector(1536), nullable=False)  # Azure OpenAI

# A:
embedding = Column(Vector(768), nullable=False)   # Gemini
```

O mejor, hazlo din√°mico:

```python
import os

EMBEDDING_DIMENSIONS = int(os.getenv("EMBEDDING_DIMENSIONS", "768"))

class GastoEmbedding(Base):
    # ...
    embedding = Column(Vector(EMBEDDING_DIMENSIONS), nullable=False)
```

---

## üìã PASO 6: REINICIAR DOCKER

```bash
docker-compose down
docker-compose up -d
```

---

## üìã PASO 7: PROBAR CONEXI√ìN

```bash
docker exec analizador-backend python << EOF
import os
os.environ['EMBEDDING_PROVIDER'] = 'gemini'
os.environ['GEMINI_API_KEY'] = 'TU_API_KEY'

from app.services.embeddings_service import EmbeddingsService

service = EmbeddingsService()
embedding = service.generate_embedding("Test de embedding con Gemini")

if embedding:
    print(f"‚úÖ Embedding generado: {len(embedding)} dimensiones")
    print(f"Primeros 5 valores: {embedding[:5]}")
else:
    print("‚ùå Error generando embedding")
EOF
```

---

## üìã PASO 8: MIGRAR DATOS EXISTENTES

```bash
cd backend
./scripts/migrar_embeddings.sh
```

Deber√≠as ver:

```
[1/9] Procesando gasto #1... ‚úÖ
[2/9] Procesando gasto #2... ‚úÖ
...
‚úÖ Migraci√≥n completada exitosamente!
```

---

## üîç VERIFICACI√ìN

### Verificar embeddings en BD:

```bash
docker exec analizador-postgres psql -U unlam -d analizador_financiero -c "
SELECT 
    COUNT(*) as total,
    AVG(array_length(embedding::float[], 1)) as avg_dimensions
FROM gastos_embeddings;
"
```

Deber√≠as ver:
```
 total | avg_dimensions 
-------+----------------
     9 |            768
```

---

## üÜö COMPARACI√ìN: AZURE vs GEMINI

| Feature | Azure OpenAI | Google Gemini |
|---------|--------------|---------------|
| **Costo** | $0.02 / 1M tokens | **GRATIS** (1500/d√≠a) |
| **Dimensiones** | 1536 | 768 |
| **Calidad** | Excelente | Muy buena |
| **Velocidad** | R√°pido | Muy r√°pido |
| **L√≠mites** | Seg√∫n tier | 1500 req/d√≠a (free) |
| **Restricciones** | Por regi√≥n | Globales ‚úÖ |
| **Setup** | Deployment complejo | Solo API key ‚úÖ |

---

## üí° RECOMENDACI√ìN

Para tu caso de uso (26 registros existentes + crecimiento gradual):

‚úÖ **USA GEMINI**
- Gratis y suficiente
- M√°s f√°cil de configurar
- 768 dimensiones son perfectas para tu escala

M√°s adelante, si crec√©s mucho o necesit√°s mejor rendimiento, pod√©s migrar a Azure OpenAI.

---

## üÜò TROUBLESHOOTING

### Error: "API key not valid"
```bash
# Verificar que la API key est√© bien configurada
docker exec analizador-backend env | grep GEMINI_API_KEY
```

### Error: "Module google.generativeai not found"
```bash
# Instalar dependencia
docker exec analizador-backend pip install google-generativeai==0.3.2
```

### Error: "Dimension mismatch"
```bash
# Recrear tablas con 768 dimensiones (ver Paso 4)
```

---

## ‚úÖ CHECKLIST FINAL

- [ ] Obtener API key de Google AI Studio
- [ ] Agregar `EMBEDDING_PROVIDER=gemini` y `GEMINI_API_KEY` al `.env`
- [ ] Instalar `google-generativeai` en requirements.txt
- [ ] Recrear tablas de embeddings con 768 dimensiones
- [ ] Reiniciar Docker
- [ ] Probar conexi√≥n con Gemini
- [ ] Ejecutar migraci√≥n de datos existentes
- [ ] Verificar embeddings en BD
- [ ] Probar chat con b√∫squeda sem√°ntica

---

¬°Listo! Ahora tu sistema usa Gemini para embeddings (gratis) y Azure OpenAI para chat. üöÄ
